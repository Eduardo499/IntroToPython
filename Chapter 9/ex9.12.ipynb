{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0af6c96d-4779-4a67-98b7-691010559836",
   "metadata": {},
   "source": [
    "(Project: State-of-the-Union Speeches) Text files of all U.S. Presidents’ State-of-the-Union speeches are available online. Download one of these speeches. Write a script that reads the speech from the file, then displays statistics about the speech, including the total word count, the total character count, the average word length, the average sentence\n",
    "length, a word distribution of the words frequencies, and the top 10 longest words. In the “Natural Language Processing (NLP)” chapter, you’ll find lots of more sophisticated techniques for analyzing and comparing such texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4855842-0bff-475f-a02b-2497155156c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Analysis Results\n",
      "========================\n",
      "Total Word Count: 2863\n",
      "Total Character Count: 14165\n",
      "Average Word Length: 4.95\n",
      "Average Sentence Length: 34.49 words\n",
      "\n",
      "Top 10 Longest Words:\n",
      "representatives\n",
      "disappointments\n",
      "establishments\n",
      "procrastinated\n",
      "communications\n",
      "michelimackina\n",
      "appropriations\n",
      "extinguishment\n",
      "administration\n",
      "inconveniences\n",
      "\n",
      "Word Frequency Distribution (Top 20):\n",
      "the: 262\n",
      "of: 192\n",
      "to: 112\n",
      "and: 94\n",
      "in: 67\n",
      "a: 57\n",
      "be: 40\n",
      "for: 35\n",
      "that: 31\n",
      "our: 28\n",
      "which: 26\n",
      "it: 26\n",
      "with: 23\n",
      "is: 23\n",
      "will: 21\n",
      "have: 20\n",
      "by: 20\n",
      "i: 19\n",
      "as: 19\n",
      "on: 19\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "def analyze_speech(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    cleaned_text = clean_text(text)\n",
    "\n",
    "    words = re.findall(r'\\b\\w+\\b', cleaned_text)\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "\n",
    "    total_word_count = len(words)\n",
    "\n",
    "    total_character_count = sum(len(word) for word in words)\n",
    "\n",
    "    avg_word_length = total_character_count / total_word_count if total_word_count > 0 else 0\n",
    "\n",
    "    avg_sentence_length = total_word_count / len(sentences) if len(sentences) > 0 else 0\n",
    "\n",
    "    word_distribution = Counter(words)\n",
    "\n",
    "    unique_words = set(words)\n",
    "    longest_words = sorted(unique_words, key=len, reverse=True)[:10]\n",
    "\n",
    "    return {\n",
    "        \"total_word_count\": total_word_count,\n",
    "        \"total_character_count\": total_character_count,\n",
    "        \"avg_word_length\": avg_word_length,\n",
    "        \"avg_sentence_length\": avg_sentence_length,\n",
    "        \"word_distribution\": word_distribution,\n",
    "        \"longest_words\": longest_words,\n",
    "    }\n",
    "\n",
    "def display_results(results):\n",
    "    \"\"\"Display the analysis results.\"\"\"\n",
    "    print(\"Speech Analysis Results\")\n",
    "    print(\"========================\")\n",
    "    print(f\"Total Word Count: {results['total_word_count']}\")\n",
    "    print(f\"Total Character Count: {results['total_character_count']}\")\n",
    "    print(f\"Average Word Length: {results['avg_word_length']:.2f}\")\n",
    "    print(f\"Average Sentence Length: {results['avg_sentence_length']:.2f} words\\n\")\n",
    "    \n",
    "    print(\"Top 10 Longest Words:\")\n",
    "    for word in results['longest_words']:\n",
    "        print(word)\n",
    "    \n",
    "    print(\"\\nWord Frequency Distribution (Top 20):\")\n",
    "    for word, count in results['word_distribution'].most_common(20):\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "input_file = \"state_of_the_union.txt\" \n",
    "\n",
    "results = analyze_speech(input_file)\n",
    "\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba4522-8bf0-49f1-a7ca-85c994c6426c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
